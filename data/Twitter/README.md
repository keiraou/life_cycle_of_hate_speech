# Datasets:
================================

**1. Hate Speech Twitter annotations**

- Classification Categories:  [sexism, racism] 
- Link: https://github.com/zeeraktalat/hatespeech 

~~~
@InProceedings{waseem-hovy:2016:N16-2,
  author    = {Waseem, Zeerak  and  Hovy, Dirk},
  title     = {Hateful Symbols or Hateful People? Predictive Features for Hate Speech Detection on Twitter},
  booktitle = {Proceedings of the NAACL Student Research Workshop},
  month     = {June},
  year      = {2016},
  address   = {San Diego, California},
  publisher = {Association for Computational Linguistics},
  pages     = {88--93},
  url       = {http://www.aclweb.org/anthology/N16-2013}
}
~~~


**2. Toxic comment annotations**

the Conversation AI team, a research initiative founded by Jigsaw and Google (both a part of Alphabet) are working on tools to help improve online conversation. They have published two Kaggle challenges with unstructured online comment dataset with labeling informed by the Online Hate Index Research Project at D-Lab, University of California, Berkeley

- Classification Categories: [toxic, severe_toxic, obscene, threat, insult, identity_hate]
- Link: https://www.kaggle.com/competitions/jigsaw-unintended-bias-in-toxicity-classification/data; https://www.kaggle.com/competitions/jigsaw-toxic-comment-classification-challenge/overview




