{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "moved-wright",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, classification_report\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold, cross_val_score\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "corporate-charlotte",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/Twitter/hate_twitter/hate_train.csv')\n",
    "val_df = pd.read_csv('data/Twitter/hate_twitter/hate_val.csv')\n",
    "test_df = pd.read_csv('data/Twitter/hate_twitter/hate_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "overhead-washer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check and drop na values in clean_tweet column\n",
    "train_df[train_df['clean_tweet'].isnull()]\n",
    "\n",
    "train_df = train_df[train_df['clean_tweet'].notna()]\n",
    "val_df = val_df[val_df['clean_tweet'].notna()]\n",
    "test_df = test_df[test_df['clean_tweet'].notna()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "empty-superintendent",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>hash_tag</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>tokenized_tweet</th>\n",
       "      <th>tokenized_tweet_NLTK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27857</td>\n",
       "      <td>27857</td>\n",
       "      <td>27858</td>\n",
       "      <td>0</td>\n",
       "      <td>omg. omg. omg.  yay! i found it, and at a wond...</td>\n",
       "      <td>['segasaturn', 'throwbackâ']</td>\n",
       "      <td>omg omg omg yay found wonderful price segasatu...</td>\n",
       "      <td>omg. omg. omg.  yay! i found it, and at a wond...</td>\n",
       "      <td>omg omg omg yay found wonderful price segasatu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31205</td>\n",
       "      <td>31205</td>\n",
       "      <td>31206</td>\n",
       "      <td>0</td>\n",
       "      <td>#payintheusa   polar bear climb racing: angry ...</td>\n",
       "      <td>['payintheusa']</td>\n",
       "      <td>payintheusa polar bear climb racing angry pola...</td>\n",
       "      <td>&lt;hashtag&gt; payintheusa  &lt;elong&gt;polar bear climb...</td>\n",
       "      <td>payintheusa polar bear climb racing angry pola...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8440</td>\n",
       "      <td>8440</td>\n",
       "      <td>8441</td>\n",
       "      <td>0</td>\n",
       "      <td>#trainhard   polar bear climb racing: angry po...</td>\n",
       "      <td>['trainhard']</td>\n",
       "      <td>trainhard polar bear climb racing angry polar ...</td>\n",
       "      <td>&lt;hashtag&gt; trainhard  &lt;elong&gt;polar bear climb r...</td>\n",
       "      <td>trainhard polar bear climb racing angry polar ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5005</td>\n",
       "      <td>5005</td>\n",
       "      <td>5006</td>\n",
       "      <td>1</td>\n",
       "      <td>he should turn in his resignation.</td>\n",
       "      <td>[]</td>\n",
       "      <td>turn resignation</td>\n",
       "      <td>he should turn in his resignation.</td>\n",
       "      <td>turn resignation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3898</td>\n",
       "      <td>3898</td>\n",
       "      <td>3899</td>\n",
       "      <td>0</td>\n",
       "      <td>ððð . . happy bihday!! to hajime hoso...</td>\n",
       "      <td>['bihday', '30æ', 'ã']</td>\n",
       "      <td>happy bihday hajime hosogai bihday bihday 30</td>\n",
       "      <td>ððð . . happy bihday! &lt;repeat&gt; to haj...</td>\n",
       "      <td>. . happy bihday hajime hosogai . . . bihday b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1     id  label  \\\n",
       "0       27857         27857  27858      0   \n",
       "1       31205         31205  31206      0   \n",
       "2        8440          8440   8441      0   \n",
       "3        5005          5005   5006      1   \n",
       "4        3898          3898   3899      0   \n",
       "\n",
       "                                               tweet  \\\n",
       "0  omg. omg. omg.  yay! i found it, and at a wond...   \n",
       "1  #payintheusa   polar bear climb racing: angry ...   \n",
       "2  #trainhard   polar bear climb racing: angry po...   \n",
       "3                he should turn in his resignation.    \n",
       "4  ððð . . happy bihday!! to hajime hoso...   \n",
       "\n",
       "                       hash_tag  \\\n",
       "0  ['segasaturn', 'throwbackâ']   \n",
       "1               ['payintheusa']   \n",
       "2                 ['trainhard']   \n",
       "3                            []   \n",
       "4        ['bihday', '30æ', 'ã']   \n",
       "\n",
       "                                         clean_tweet  \\\n",
       "0  omg omg omg yay found wonderful price segasatu...   \n",
       "1  payintheusa polar bear climb racing angry pola...   \n",
       "2  trainhard polar bear climb racing angry polar ...   \n",
       "3                                   turn resignation   \n",
       "4       happy bihday hajime hosogai bihday bihday 30   \n",
       "\n",
       "                                     tokenized_tweet  \\\n",
       "0  omg. omg. omg.  yay! i found it, and at a wond...   \n",
       "1  <hashtag> payintheusa  <elong>polar bear climb...   \n",
       "2  <hashtag> trainhard  <elong>polar bear climb r...   \n",
       "3                he should turn in his resignation.    \n",
       "4  ððð . . happy bihday! <repeat> to haj...   \n",
       "\n",
       "                                tokenized_tweet_NLTK  \n",
       "0  omg omg omg yay found wonderful price segasatu...  \n",
       "1  payintheusa polar bear climb racing angry pola...  \n",
       "2  trainhard polar bear climb racing angry polar ...  \n",
       "3                                   turn resignation  \n",
       "4  . . happy bihday hajime hosogai . . . bihday b...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abroad-genesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_df['clean_tweet']\n",
    "y_train = train_df['label']\n",
    "\n",
    "x_test = test_df['clean_tweet']\n",
    "y_test = test_df['label']\n",
    "\n",
    "x_val = val_df['clean_tweet']\n",
    "y_val = val_df['label']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "purple-search",
   "metadata": {},
   "source": [
    "# Deal with data imbalance, upsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "three-series",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "surrounded-regular",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    20776\n",
       "1    20776\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_majority = train_df[train_df.label==0]\n",
    "train_minority = train_df[train_df.label==1]\n",
    "train_minority_upsampled = resample(train_minority, \n",
    "                                 replace=True,    \n",
    "                                 n_samples=len(train_majority),   \n",
    "                                 random_state=123)\n",
    "train_upsampled = pd.concat([train_minority_upsampled, train_majority])\n",
    "train_upsampled['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "metallic-marketplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_upsampled = train_upsampled['clean_tweet']\n",
    "y_train_upsampled = train_upsampled['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identified-championship",
   "metadata": {},
   "source": [
    "# Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "growing-florida",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eight-transport",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bow_pipeline(train_df, test_df, val_df, ngram_range=(1,1)):\n",
    "    '''\n",
    "    Pipeline for Bag-of-words based models training and evaluation\n",
    "    '''\n",
    "    cls = [LogisticRegression(),\n",
    "           MultinomialNB(), \n",
    "           SVC(),\n",
    "           LinearSVC(C=0.01),\n",
    "           GradientBoostingClassifier(),\n",
    "           xgb.XGBClassifier(use_label =False),\n",
    "           RandomForestClassifier(n_estimators=200),\n",
    "           KNeighborsClassifier(n_neighbors = 5)]\n",
    "    \n",
    "    result_all_dict = {}\n",
    "\n",
    "    vectorizer = CountVectorizer()\n",
    "    train_model = vectorizer.fit_transform(train_df.clean_tweet)\n",
    "    test_model = vectorizer.transform(test_df.clean_tweet)\n",
    "    val_model = vectorizer.transform(val_df.clean_tweet)\n",
    "\n",
    "    train_tfidf = pd.DataFrame(train_model)\n",
    "\n",
    "    test_actual = test_df.label\n",
    "    val_actual = val_df.label\n",
    "    i = 0\n",
    "    accuracy = []\n",
    "    cls_name = []\n",
    "\n",
    "    for cl in cls:\n",
    "        result_dict = {}\n",
    "            \n",
    "        model = cl.fit(train_model,train_df.label)\n",
    "        \n",
    "        y_test_predict = model.predict(test_model)\n",
    "        y_val_predict = model.predict(val_model)\n",
    "        \n",
    "        a = (100*accuracy_score(y_val_predict, val_actual))\n",
    "        a = round(a,2)\n",
    "        accuracy.append(a)\n",
    "        cls_name.append(cl.__class__.__name__)\n",
    "        \n",
    "        result_dict[\"Validation Accuracy\"] = accuracy_score(y_val_predict, val_actual)\n",
    "        result_dict[\"Validation Binary Recall\"] = recall_score(y_val_predict, val_actual)\n",
    "        result_dict[\"Validation Macro Recall\"] = recall_score(y_val_predict, val_actual, average='macro')\n",
    "        result_dict[\"Validation Binary F1\"] = f1_score(y_val_predict, val_actual)\n",
    "        result_dict[\"Validation Macro F1\"] = f1_score(y_val_predict, val_actual, average='macro')\n",
    "        result_dict[\"Test Accuracy\"] = accuracy_score(y_test_predict, test_actual)\n",
    "        result_dict[\"Test Binary Recall\"] = recall_score(y_test_predict, test_actual)\n",
    "        result_dict[\"Test Macro Recall\"] = recall_score(y_test_predict, test_actual, average='macro')\n",
    "        result_dict[\"Test Binary F1\"] = f1_score(y_test_predict, test_actual)\n",
    "        result_dict[\"Test Macro F1\"] = f1_score(y_test_predict, test_actual, average='macro')\n",
    "        \n",
    "        result_all_dict[cl.__class__.__name__] = result_dict\n",
    "        \n",
    "        i +=1\n",
    "    \n",
    "    return result_all_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exotic-civilization",
   "metadata": {},
   "source": [
    "## Original data frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "accepted-navigation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:00:52] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-3.7/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"use_label\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_all_dict = bow_pipeline(train_df, test_df, val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "insured-invasion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <th>Validation Binary Recall</th>\n",
       "      <th>Validation Macro Recall</th>\n",
       "      <th>Validation Binary F1</th>\n",
       "      <th>Validation Macro F1</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Test Binary Recall</th>\n",
       "      <th>Test Macro Recall</th>\n",
       "      <th>Test Binary F1</th>\n",
       "      <th>Test Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.960752</td>\n",
       "      <td>0.910526</td>\n",
       "      <td>0.936676</td>\n",
       "      <td>0.647940</td>\n",
       "      <td>0.813579</td>\n",
       "      <td>0.963272</td>\n",
       "      <td>0.896175</td>\n",
       "      <td>0.931056</td>\n",
       "      <td>0.650794</td>\n",
       "      <td>0.815705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MultinomialNB</th>\n",
       "      <td>0.958246</td>\n",
       "      <td>0.867347</td>\n",
       "      <td>0.914736</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.803753</td>\n",
       "      <td>0.959933</td>\n",
       "      <td>0.817734</td>\n",
       "      <td>0.891979</td>\n",
       "      <td>0.633588</td>\n",
       "      <td>0.806198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.955115</td>\n",
       "      <td>0.932886</td>\n",
       "      <td>0.944357</td>\n",
       "      <td>0.563895</td>\n",
       "      <td>0.770117</td>\n",
       "      <td>0.959516</td>\n",
       "      <td>0.931973</td>\n",
       "      <td>0.946180</td>\n",
       "      <td>0.585470</td>\n",
       "      <td>0.782094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>0.946138</td>\n",
       "      <td>0.957447</td>\n",
       "      <td>0.951679</td>\n",
       "      <td>0.410959</td>\n",
       "      <td>0.691369</td>\n",
       "      <td>0.952212</td>\n",
       "      <td>0.933962</td>\n",
       "      <td>0.943294</td>\n",
       "      <td>0.463700</td>\n",
       "      <td>0.719346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier</th>\n",
       "      <td>0.945094</td>\n",
       "      <td>0.917526</td>\n",
       "      <td>0.931595</td>\n",
       "      <td>0.403628</td>\n",
       "      <td>0.687425</td>\n",
       "      <td>0.949708</td>\n",
       "      <td>0.892157</td>\n",
       "      <td>0.921558</td>\n",
       "      <td>0.430260</td>\n",
       "      <td>0.701976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.949896</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.917111</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.736813</td>\n",
       "      <td>0.955968</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.912760</td>\n",
       "      <td>0.552017</td>\n",
       "      <td>0.764432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.956994</td>\n",
       "      <td>0.841584</td>\n",
       "      <td>0.901830</td>\n",
       "      <td>0.622711</td>\n",
       "      <td>0.799954</td>\n",
       "      <td>0.962646</td>\n",
       "      <td>0.858586</td>\n",
       "      <td>0.912858</td>\n",
       "      <td>0.655106</td>\n",
       "      <td>0.817680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.937787</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.893760</td>\n",
       "      <td>0.273171</td>\n",
       "      <td>0.620337</td>\n",
       "      <td>0.941987</td>\n",
       "      <td>0.811594</td>\n",
       "      <td>0.877743</td>\n",
       "      <td>0.287179</td>\n",
       "      <td>0.628471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Validation Accuracy  Validation Binary Recall  \\\n",
       "LogisticRegression                     0.960752                  0.910526   \n",
       "MultinomialNB                          0.958246                  0.867347   \n",
       "SVC                                    0.955115                  0.932886   \n",
       "LinearSVC                              0.946138                  0.957447   \n",
       "GradientBoostingClassifier             0.945094                  0.917526   \n",
       "XGBClassifier                          0.949896                  0.882353   \n",
       "RandomForestClassifier                 0.956994                  0.841584   \n",
       "KNeighborsClassifier                   0.937787                  0.848485   \n",
       "\n",
       "                            Validation Macro Recall  Validation Binary F1  \\\n",
       "LogisticRegression                         0.936676              0.647940   \n",
       "MultinomialNB                              0.914736              0.629630   \n",
       "SVC                                        0.944357              0.563895   \n",
       "LinearSVC                                  0.951679              0.410959   \n",
       "GradientBoostingClassifier                 0.931595              0.403628   \n",
       "XGBClassifier                              0.917111              0.500000   \n",
       "RandomForestClassifier                     0.901830              0.622711   \n",
       "KNeighborsClassifier                       0.893760              0.273171   \n",
       "\n",
       "                            Validation Macro F1  Test Accuracy  \\\n",
       "LogisticRegression                     0.813579       0.963272   \n",
       "MultinomialNB                          0.803753       0.959933   \n",
       "SVC                                    0.770117       0.959516   \n",
       "LinearSVC                              0.691369       0.952212   \n",
       "GradientBoostingClassifier             0.687425       0.949708   \n",
       "XGBClassifier                          0.736813       0.955968   \n",
       "RandomForestClassifier                 0.799954       0.962646   \n",
       "KNeighborsClassifier                   0.620337       0.941987   \n",
       "\n",
       "                            Test Binary Recall  Test Macro Recall  \\\n",
       "LogisticRegression                    0.896175           0.931056   \n",
       "MultinomialNB                         0.817734           0.891979   \n",
       "SVC                                   0.931973           0.946180   \n",
       "LinearSVC                             0.933962           0.943294   \n",
       "GradientBoostingClassifier            0.892157           0.921558   \n",
       "XGBClassifier                         0.866667           0.912760   \n",
       "RandomForestClassifier                0.858586           0.912858   \n",
       "KNeighborsClassifier                  0.811594           0.877743   \n",
       "\n",
       "                            Test Binary F1  Test Macro F1  \n",
       "LogisticRegression                0.650794       0.815705  \n",
       "MultinomialNB                     0.633588       0.806198  \n",
       "SVC                               0.585470       0.782094  \n",
       "LinearSVC                         0.463700       0.719346  \n",
       "GradientBoostingClassifier        0.430260       0.701976  \n",
       "XGBClassifier                     0.552017       0.764432  \n",
       "RandomForestClassifier            0.655106       0.817680  \n",
       "KNeighborsClassifier              0.287179       0.628471  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_pd = pd.DataFrame.from_dict(result_all_dict, orient='index')\n",
    "result_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fluid-hawaiian",
   "metadata": {},
   "source": [
    "## Upsampled data frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "rental-translation",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:05:12] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-3.7/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"use_label\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Upsampled data frame\n",
    "result_all_dict_upsampled = bow_pipeline(train_upsampled, test_df, val_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "norman-cambodia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <th>Validation Binary Recall</th>\n",
       "      <th>Validation Macro Recall</th>\n",
       "      <th>Validation Binary F1</th>\n",
       "      <th>Validation Macro F1</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Test Binary Recall</th>\n",
       "      <th>Test Macro Recall</th>\n",
       "      <th>Test Binary F1</th>\n",
       "      <th>Test Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.948434</td>\n",
       "      <td>0.633609</td>\n",
       "      <td>0.803929</td>\n",
       "      <td>0.650636</td>\n",
       "      <td>0.811400</td>\n",
       "      <td>0.952629</td>\n",
       "      <td>0.629834</td>\n",
       "      <td>0.804421</td>\n",
       "      <td>0.667643</td>\n",
       "      <td>0.821070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MultinomialNB</th>\n",
       "      <td>0.925261</td>\n",
       "      <td>0.487762</td>\n",
       "      <td>0.736176</td>\n",
       "      <td>0.609170</td>\n",
       "      <td>0.783925</td>\n",
       "      <td>0.921745</td>\n",
       "      <td>0.453608</td>\n",
       "      <td>0.720035</td>\n",
       "      <td>0.584718</td>\n",
       "      <td>0.770760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.961378</td>\n",
       "      <td>0.866359</td>\n",
       "      <td>0.916123</td>\n",
       "      <td>0.670232</td>\n",
       "      <td>0.824860</td>\n",
       "      <td>0.963063</td>\n",
       "      <td>0.839623</td>\n",
       "      <td>0.904200</td>\n",
       "      <td>0.667917</td>\n",
       "      <td>0.824181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>0.940084</td>\n",
       "      <td>0.564334</td>\n",
       "      <td>0.771355</td>\n",
       "      <td>0.635324</td>\n",
       "      <td>0.801342</td>\n",
       "      <td>0.940735</td>\n",
       "      <td>0.541387</td>\n",
       "      <td>0.761603</td>\n",
       "      <td>0.630208</td>\n",
       "      <td>0.798997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier</th>\n",
       "      <td>0.932777</td>\n",
       "      <td>0.531609</td>\n",
       "      <td>0.747907</td>\n",
       "      <td>0.534682</td>\n",
       "      <td>0.749227</td>\n",
       "      <td>0.936561</td>\n",
       "      <td>0.522788</td>\n",
       "      <td>0.747137</td>\n",
       "      <td>0.561960</td>\n",
       "      <td>0.763882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.932777</td>\n",
       "      <td>0.524336</td>\n",
       "      <td>0.749835</td>\n",
       "      <td>0.595477</td>\n",
       "      <td>0.779410</td>\n",
       "      <td>0.937187</td>\n",
       "      <td>0.522624</td>\n",
       "      <td>0.750967</td>\n",
       "      <td>0.605505</td>\n",
       "      <td>0.785691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.953445</td>\n",
       "      <td>0.721612</td>\n",
       "      <td>0.844534</td>\n",
       "      <td>0.638574</td>\n",
       "      <td>0.806847</td>\n",
       "      <td>0.960351</td>\n",
       "      <td>0.750958</td>\n",
       "      <td>0.861685</td>\n",
       "      <td>0.673540</td>\n",
       "      <td>0.826217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.901461</td>\n",
       "      <td>0.359031</td>\n",
       "      <td>0.658644</td>\n",
       "      <td>0.408521</td>\n",
       "      <td>0.677388</td>\n",
       "      <td>0.901294</td>\n",
       "      <td>0.339662</td>\n",
       "      <td>0.651304</td>\n",
       "      <td>0.405031</td>\n",
       "      <td>0.675607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Validation Accuracy  Validation Binary Recall  \\\n",
       "LogisticRegression                     0.948434                  0.633609   \n",
       "MultinomialNB                          0.925261                  0.487762   \n",
       "SVC                                    0.961378                  0.866359   \n",
       "LinearSVC                              0.940084                  0.564334   \n",
       "GradientBoostingClassifier             0.932777                  0.531609   \n",
       "XGBClassifier                          0.932777                  0.524336   \n",
       "RandomForestClassifier                 0.953445                  0.721612   \n",
       "KNeighborsClassifier                   0.901461                  0.359031   \n",
       "\n",
       "                            Validation Macro Recall  Validation Binary F1  \\\n",
       "LogisticRegression                         0.803929              0.650636   \n",
       "MultinomialNB                              0.736176              0.609170   \n",
       "SVC                                        0.916123              0.670232   \n",
       "LinearSVC                                  0.771355              0.635324   \n",
       "GradientBoostingClassifier                 0.747907              0.534682   \n",
       "XGBClassifier                              0.749835              0.595477   \n",
       "RandomForestClassifier                     0.844534              0.638574   \n",
       "KNeighborsClassifier                       0.658644              0.408521   \n",
       "\n",
       "                            Validation Macro F1  Test Accuracy  \\\n",
       "LogisticRegression                     0.811400       0.952629   \n",
       "MultinomialNB                          0.783925       0.921745   \n",
       "SVC                                    0.824860       0.963063   \n",
       "LinearSVC                              0.801342       0.940735   \n",
       "GradientBoostingClassifier             0.749227       0.936561   \n",
       "XGBClassifier                          0.779410       0.937187   \n",
       "RandomForestClassifier                 0.806847       0.960351   \n",
       "KNeighborsClassifier                   0.677388       0.901294   \n",
       "\n",
       "                            Test Binary Recall  Test Macro Recall  \\\n",
       "LogisticRegression                    0.629834           0.804421   \n",
       "MultinomialNB                         0.453608           0.720035   \n",
       "SVC                                   0.839623           0.904200   \n",
       "LinearSVC                             0.541387           0.761603   \n",
       "GradientBoostingClassifier            0.522788           0.747137   \n",
       "XGBClassifier                         0.522624           0.750967   \n",
       "RandomForestClassifier                0.750958           0.861685   \n",
       "KNeighborsClassifier                  0.339662           0.651304   \n",
       "\n",
       "                            Test Binary F1  Test Macro F1  \n",
       "LogisticRegression                0.667643       0.821070  \n",
       "MultinomialNB                     0.584718       0.770760  \n",
       "SVC                               0.667917       0.824181  \n",
       "LinearSVC                         0.630208       0.798997  \n",
       "GradientBoostingClassifier        0.561960       0.763882  \n",
       "XGBClassifier                     0.605505       0.785691  \n",
       "RandomForestClassifier            0.673540       0.826217  \n",
       "KNeighborsClassifier              0.405031       0.675607  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_pd_upsampled = pd.DataFrame.from_dict(result_all_dict_upsampled, orient='index')\n",
    "result_pd_upsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ready-there",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "connected-safety",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weekly-criterion",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clean-finding",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "possible-effectiveness",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
